% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Bias - variance tradeoff in time series},
  pdfauthor={Caglar Altunel},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Bias - variance tradeoff in time series}
\author{Caglar Altunel}
\date{12/24/2020}

\begin{document}
\maketitle

\hypertarget{bias-variance-tradeoff-in-time-series}{%
\subsubsection{Bias-variance tradeoff in time
series}\label{bias-variance-tradeoff-in-time-series}}

Bias-variance tradeoff is an important concept that one must always pay
regard when modelling for both prediction and forecasting purposes.
There are several measures that provides us what the best fit is for our
dataset while modelling, such as minimum mean squared error, AIC etc.
However, while minimizing these values, we may create a model that
captures almost the entire bias (low bias) in the data that use for
modelling, but significantly fails in another data simply because that
happens to be ``so specific'' for the dataset we used (high variance).
This is called overfitting, refers to when a statistical model
incorporates noise rather than real patterns in the data. Long story
short, while making our model less biased, we increase variance.
Therefore, we must build models that can be generalized so that we reach
more or less the same accuracy when tested on a different dataset. Below
codes provides an example of bias-variance tradeoff and overfitting in
time series. Here the target is to forecast final consumption
expenditure of Australia, for the period quarter one of 2013 - quarter
four of 2018, by making use of the training time series quarter two of
1959 - quarter four of 2012. The dataset can be downloaded from:
\url{https://stats.oecd.org/Index.aspx?DataSetCode=QNA}. I would like to
thank so much to my thesis partner, Hallvard Holte for his exceptional
contribution.

Let's start with loading the essential packages.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(fpp2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'fpp2' was built under R version 3.6.3
\end{verbatim}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{verbatim}
## Loading required package: forecast
\end{verbatim}

\begin{verbatim}
## Registered S3 method overwritten by 'quantmod':
##   method            from
##   as.zoo.data.frame zoo
\end{verbatim}

\begin{verbatim}
## Loading required package: fma
\end{verbatim}

\begin{verbatim}
## Warning: package 'fma' was built under R version 3.6.3
\end{verbatim}

\begin{verbatim}
## Loading required package: expsmooth
\end{verbatim}

\begin{verbatim}
## Warning: package 'expsmooth' was built under R version 3.6.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(seasonal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'seasonal' was built under R version 3.6.3
\end{verbatim}

\hypertarget{loading-data-and-decomposition}{%
\paragraph{Loading data and
decomposition}\label{loading-data-and-decomposition}}

This is here the dataset is downloaded to, so I set this as working
directory.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"C:/Users/Caglar/Desktop/Github"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Below codes loads to dataset to R environment as time series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cons =}\StringTok{ }\KeywordTok{ts}\NormalTok{(}\KeywordTok{scan}\NormalTok{(}\StringTok{"cons.txt"}\NormalTok{),}\DataTypeTok{start=}\FloatTok{1959.5}\NormalTok{,}\DataTypeTok{frequency=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The dataset is divided into two, train and test, so that we will test
the model on a new dataset to figure out whether overfitting occurs or
not. The period, from Q1 2013 onwards, to be forecasted, therefore it is
filtered out as the test data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cons_train =}\StringTok{ }\KeywordTok{window}\NormalTok{(cons,}\DataTypeTok{end=}\DecValTok{2013}\NormalTok{)}
\NormalTok{cons_test =}\StringTok{ }\KeywordTok{window}\NormalTok{(cons,}\DataTypeTok{start=}\FloatTok{2013.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

First, training data is decomposed to see trend and seasonality. It can
be seen (the output of the below code) from the systematic variations
that seasonality is quite strong in the data. Time series has an obvious
upward trend too. At the first place, data will be stationarized (The
impact of trend and seasonality will be erased so the data we will use
for modelling will have no or very limited temporal patterns.) in order
to make it ready for time series modelling.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{consumption_x11=}\KeywordTok{seas}\NormalTok{(cons_train, }\DataTypeTok{x11=}\StringTok{""}\NormalTok{) }\CommentTok{#decomposition of consumption using X11}
\KeywordTok{autoplot}\NormalTok{(consumption_x11)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"X11 decomposition of Consumption"}\NormalTok{)}\OperatorTok{+}\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-5-1.pdf}

\hypertarget{how-to-make-the-data-stationary}{%
\paragraph{How to make the data
stationary}\label{how-to-make-the-data-stationary}}

In order to stabilize the trend, time series is log-scaled by the below
code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cons_log =}\StringTok{ }\KeywordTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{215}\NormalTok{)\{}
\NormalTok{  cons_log=}\KeywordTok{c}\NormalTok{(cons_log,}\KeywordTok{log}\NormalTok{(cons_train[t]))}
\NormalTok{\}}

\NormalTok{cons_log =}\StringTok{ }\KeywordTok{ts}\NormalTok{(cons_log,}\DataTypeTok{start=}\FloatTok{1959.5}\NormalTok{,}\DataTypeTok{frequency=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

It can be seen from the below plot that the trend is still there, but at
least it is no longer exponential. Further modifications needed to erase
the temporal pattern.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{autoplot}\NormalTok{(cons_log,}\DataTypeTok{series=}\StringTok{"Log consumption expenditure"}\NormalTok{,}\DataTypeTok{xlab=}\StringTok{"Year"}\NormalTok{,}\DataTypeTok{ylab=}\StringTok{"log Mill AUD"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-7-1.pdf}

As a second step, a seasonal log-difference transformation is pursued to
see whether we manage to reduce the temporal effect in the data or not.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cons_sld =}\StringTok{ }\KeywordTok{c}\NormalTok{() }\CommentTok{#Seasonal log-diff transformation}

\ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{5}\OperatorTok{:}\DecValTok{215}\NormalTok{)\{}
\NormalTok{  cons_sld=}\KeywordTok{c}\NormalTok{(cons_sld,}\KeywordTok{log}\NormalTok{(cons_train[t])}\OperatorTok{-}\KeywordTok{log}\NormalTok{(cons_train[t}\DecValTok{-4}\NormalTok{]))}
\NormalTok{\}}

\NormalTok{cons_sld =}\StringTok{ }\KeywordTok{ts}\NormalTok{(cons_sld,}\DataTypeTok{start=}\FloatTok{1959.5}\NormalTok{,}\DataTypeTok{frequency=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output suggests the trend is managed to be erased, but still a
noticeable seasonality left (There are systematic spikes in the data.).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{autoplot}\NormalTok{(cons_sld,}\DataTypeTok{series=}\StringTok{"Seasonal log-diff cons. expenditure"}\NormalTok{,}\DataTypeTok{xlab=}\StringTok{"Year"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-9-1.pdf}

As a final step, we take the first difference of seasonally
log-differenced dataset, to reduce the seasonality that we spotted
above.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# First difference of the log-seasonal diff}
\NormalTok{cons_fsld =}\StringTok{ }\KeywordTok{c}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (t }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\DecValTok{211}\NormalTok{)\{}
\NormalTok{  cons_fsld=}\KeywordTok{c}\NormalTok{(cons_fsld,cons_sld[t]}\OperatorTok{-}\NormalTok{cons_sld[t}\DecValTok{-1}\NormalTok{])}
\NormalTok{\}}

\NormalTok{cons_fsld =}\StringTok{ }\KeywordTok{ts}\NormalTok{(cons_fsld)}
\end{Highlighting}
\end{Shaded}

ACF, PACF (Please visit
\url{https://www.real-statistics.com/time-series-analysis/stochastic-processes/partial-autocorrelation-function/}
for the detailed explanation of PACF and
\url{https://www.real-statistics.com/time-series-analysis/stochastic-processes/autocorrelation-function/}
for ACF) and residuals show that the temporal pattern is deducted from
the dataset at a certain extent. The significant spikes that can be seen
in ACF and PACF will give us an idea at what degree we will use AR and
MA components.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggtsdisplay}\NormalTok{(cons_fsld)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-11-1.pdf}

\hypertarget{finding-the-best-fitting-model}{%
\paragraph{Finding the best-fitting
model}\label{finding-the-best-fitting-model}}

But beforehand, in order to exemplify how one can reach an overfitting
model as the best-fit, let's run the auto.arima() function, which
automatically gives the best-fit, with respect to the algorithm it
follows. Please visit \url{https://otexts.com/fpp2/} for the detailed
explanation of the functions that are used in this article. Please
notice that we used the log-scaled time series for modelling, as we made
transformations in the above to figure out the level of the temporal
pattern in the data. auto.arima() function gave us that the best model
is arima(2,1,1)(1,1,2) (Please visit
\url{https://otexts.com/fpp2/arima.html} for the detailed explanation of
the concept of ARIMA models.).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arima_auto=}\KeywordTok{auto.arima}\NormalTok{(cons_log) }\CommentTok{#auro.arima() function gives (2,1,1)(1,1,2)}
\KeywordTok{summary}\NormalTok{(arima_auto)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Series: cons_log 
## ARIMA(2,1,1)(1,1,2)[4] 
## 
## Coefficients:
##          ar1     ar2      ma1     sar1     sma1     sma2
##       0.5371  0.2429  -0.5773  -0.0797  -0.5241  -0.1834
## s.e.  0.1409  0.0747   0.1362   0.3783   0.3674   0.2568
## 
## sigma^2 estimated as 0.0001456:  log likelihood=632.63
## AIC=-1251.26   AICc=-1250.71   BIC=-1227.83
## 
## Training set error measures:
##                         ME       RMSE         MAE         MPE       MAPE
## Training set -0.0003805983 0.01175345 0.008933683 -0.00266028 0.08715793
##                  MASE          ACF1
## Training set 0.102754 -0.0006977315
\end{verbatim}

ACF, PACF and the normal distribution of residuals show that the model
can be deemed as unbiased, as there is also almost no temporal pattern
left.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggtsdisplay}\NormalTok{(}\KeywordTok{residuals}\NormalTok{(arima_auto))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{checkresiduals}\NormalTok{(arima_auto)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-13-2.pdf}

\begin{verbatim}
## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(2,1,1)(1,1,2)[4]
## Q* = 9.0184, df = 3, p-value = 0.02905
## 
## Model df: 6.   Total lags used: 9
\end{verbatim}

However, due to the algorithm that auto.arima() function pursues, we may
be missing the real best-fitting one. In fact, the decaying spikes until
lag 12 in PACF that we found out within our stationarized data
(ggtsdisplay(cons\_fsld)) may be pointing out the fact that a model with
three seasonally differentiated error terms is a better-fit. We will
give this a try by the below code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arima_manual=}\KeywordTok{Arima}\NormalTok{(cons_log, }\DataTypeTok{order=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{), }\DataTypeTok{seasonal=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{)) }\CommentTok{#However, ggtsdisplay(cons_fsld) shows seasonal MA(3).}
\KeywordTok{summary}\NormalTok{(arima_manual) }\CommentTok{#In fact, it has a slightly better AICc, and RMSE.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Series: cons_log 
## ARIMA(2,1,1)(0,1,3)[4] 
## 
## Coefficients:
##          ar1     ar2      ma1     sma1     sma2    sma3
##       0.5373  0.2456  -0.5783  -0.6090  -0.1415  0.0244
## s.e.  0.1391  0.0758   0.1342   0.0782   0.0770  0.0765
## 
## sigma^2 estimated as 0.0001455:  log likelihood=632.66
## AIC=-1251.32   AICc=-1250.77   BIC=-1227.89
## 
## Training set error measures:
##                        ME       RMSE         MAE          MPE       MAPE
## Training set -0.000376725 0.01175148 0.008933554 -0.002638319 0.08716457
##                   MASE          ACF1
## Training set 0.1027526 -0.0004030778
\end{verbatim}

The summary shows indeed it has slightly better AICc and RMSE compared
to ARIMA (2,1,1)(1,1,2). ACF, PACF and the distribution of residuals
point out that the model can be deemed as unbiased.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggtsdisplay}\NormalTok{(}\KeywordTok{residuals}\NormalTok{(arima_manual))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{checkresiduals}\NormalTok{(arima_manual)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-15-2.pdf}

\begin{verbatim}
## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(2,1,1)(0,1,3)[4]
## Q* = 8.8722, df = 3, p-value = 0.03104
## 
## Model df: 6.   Total lags used: 9
\end{verbatim}

\hypertarget{theoretical-acf-and-pacf-and-proposal-of-a-simplified-model}{%
\paragraph{Theoretical ACF and PACF, and proposal of a simplified
model}\label{theoretical-acf-and-pacf-and-proposal-of-a-simplified-model}}

However, we need to know how our model's theoretical ACF and PACF would
look, which reflects ACF and PACF plots theoretically if all of the
assumptions of the linear regression model hold. The equation for ARIMA
(2,1,1)(0,1,3) must be solved initially. Which is:

\begin{figure}
\centering
\includegraphics{ARIMA.jpg}
\caption{unchanged image}
\end{figure}

When it is solved for y, the outcome is:

\begin{figure}
\centering
\includegraphics{ARIMAsolved.jpg}
\caption{unchanged image}
\end{figure}

Theoretical ACF and PACF plots for the above model can be created by the
below code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Another way of identifying a model is having a look at theoretical ACF and PACF.}
\NormalTok{arma_acf=}\KeywordTok{ARMAacf}\NormalTok{(}\DataTypeTok{ar=}\KeywordTok{c}\NormalTok{(}\FloatTok{1.5373}\NormalTok{, }\FloatTok{-0.2917}\NormalTok{, }\FloatTok{-0.2456}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{,}\DecValTok{5373}\NormalTok{, }\FloatTok{0.2917}\NormalTok{, }\FloatTok{0.2456}\NormalTok{), }\DataTypeTok{ma=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{0.5783}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{-0}\NormalTok{,}\DecValTok{6090}\NormalTok{, }\FloatTok{0.3521847}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{-0.1415}\NormalTok{, }\FloatTok{0.08182945}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.0244}\NormalTok{, }\FloatTok{-0.01411052}\NormalTok{), }\DataTypeTok{lag.max=}\DecValTok{24}\NormalTok{)}
\NormalTok{arma_pacf=}\KeywordTok{ARMAacf}\NormalTok{(}\DataTypeTok{ar=}\KeywordTok{c}\NormalTok{(}\FloatTok{1.5373}\NormalTok{, }\FloatTok{-0.2917}\NormalTok{, }\FloatTok{-0.2456}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{,}\DecValTok{5373}\NormalTok{, }\FloatTok{0.2917}\NormalTok{, }\FloatTok{0.2456}\NormalTok{), }\DataTypeTok{ma=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{0.5783}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{-0}\NormalTok{,}\DecValTok{6090}\NormalTok{, }\FloatTok{0.3521847}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{-0.1415}\NormalTok{, }\FloatTok{0.08182945}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.0244}\NormalTok{, }\FloatTok{-0.01411052}\NormalTok{), }\DataTypeTok{lag.max=}\DecValTok{24}\NormalTok{, }\DataTypeTok{pacf=}\NormalTok{T)}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{pty=}\StringTok{"s"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(arma_acf[}\OperatorTok{-}\DecValTok{1}\NormalTok{],}\DataTypeTok{type=}\StringTok{"h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"lags"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"ACF"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(arma_pacf,}\DataTypeTok{type=}\StringTok{"h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"lags"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PACF"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-16-1.pdf}

It can be seen that it is far from what is obtained for our
stationarized data. Let's recall it (in the below) and see how ACF and
PACF looks like. As discussed above, now it is time to use it to build a
time series model that is very unlikely to be overfitting. Relatively
large one-time spike at lag 4 and decaying spikes from lag 4, 8, 12 and
so on point out that building a typical MA(q) model where q is the
seasonal difference.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggtsdisplay}\NormalTok{(cons_fsld) }\CommentTok{#Recall ACF and PACF of our stationerized data.}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Significant spike at lag 4 in ACF along with a decaying partial correlations of lag 4, 8 and 12.}
\CommentTok{# This points out that an MA(q) model where q is the seasonal difference would be appropriate.}
\end{Highlighting}
\end{Shaded}

The below code is to build ARIMA(0,1,0)(0,1,1)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Accordingly, lets construct an ARIMA model of (0,1,0)(0,1,1).}
\NormalTok{arima_manual2=}\KeywordTok{Arima}\NormalTok{(cons_log, }\DataTypeTok{order=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DataTypeTok{seasonal=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(arima_manual2) }\CommentTok{# Its fit is not better than ARIMA (2,1,1)(0,1,3) model.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Series: cons_log 
## ARIMA(0,1,0)(0,1,1)[4] 
## 
## Coefficients:
##          sma1
##       -0.5700
## s.e.   0.0712
## 
## sigma^2 estimated as 0.0001575:  log likelihood=622.11
## AIC=-1240.21   AICc=-1240.16   BIC=-1233.52
## 
## Training set error measures:
##                         ME       RMSE         MAE          MPE       MAPE
## Training set -0.0003863259 0.01237402 0.009530037 -0.002257481 0.09339329
##                   MASE       ACF1
## Training set 0.1096132 0.01026202
\end{verbatim}

The model's AICc is fair enough. Let's see how its ACF, PACF and
residuals look like:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggtsdisplay}\NormalTok{(}\KeywordTok{residuals}\NormalTok{(arima_manual2))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{checkresiduals}\NormalTok{(arima_manual2) }
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-19-2.pdf}

\begin{verbatim}
## 
##  Ljung-Box test
## 
## data:  Residuals from ARIMA(0,1,0)(0,1,1)[4]
## Q* = 27.665, df = 7, p-value = 0.0002529
## 
## Model df: 1.   Total lags used: 8
\end{verbatim}

Compared to our findings for the model ARIMA(2,1,1)(0,1,3), we can see
that there is more temporal pattern left in this one. In other words,
ARIMA(0,1,0)(0,1,1) captures less bias compared to ARIMA(2,1,1)(0,1,3).
That being said, ARIMA(0,1,0)(0,1,1) most likely has less variance,
therefore practically more useful for forecasting purposes. Beforehand,
let's see how theoretical ACF and PACF of ARIMA(0,1,0)(0,1,1) look like:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's see the theoretical ACF and PACF of the model implied.}
\NormalTok{arma_acf2=}\KeywordTok{ARMAacf}\NormalTok{(}\DataTypeTok{ma=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\OperatorTok{-}\FloatTok{0.57}\NormalTok{), }\DataTypeTok{lag.max=}\DecValTok{24}\NormalTok{)}
\NormalTok{arma_pacf2=}\KeywordTok{ARMAacf}\NormalTok{(}\DataTypeTok{ma=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\OperatorTok{-}\FloatTok{0.57}\NormalTok{), }\DataTypeTok{lag.max=}\DecValTok{24}\NormalTok{, }\DataTypeTok{pacf=}\NormalTok{T)}

\NormalTok{ACFmanual2=}\KeywordTok{Acf}\NormalTok{(cons_fsld)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-20-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PACFmanual2=}\KeywordTok{Acf}\NormalTok{(cons_fsld, }\DataTypeTok{type=}\KeywordTok{c}\NormalTok{(}\StringTok{"partial"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-20-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{pty=}\StringTok{"s"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(ACFmanual2, }\DataTypeTok{main=}\StringTok{""}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(PACFmanual2, }\DataTypeTok{main=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-20-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{pty=}\StringTok{"s"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(arma_acf2[}\OperatorTok{-}\DecValTok{1}\NormalTok{],}\DataTypeTok{type=}\StringTok{"h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"lags"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"ACF"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(arma_pacf2,}\DataTypeTok{type=}\StringTok{"h"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"lags"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"PACF"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-20-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Indeed variable's ACF and PACF trends looks similar with the model implied.}
\end{Highlighting}
\end{Shaded}

\hypertarget{comparing-forecast-performances}{%
\paragraph{Comparing forecast
performances}\label{comparing-forecast-performances}}

Theoretical ACF and PACF of ARIMA(0,1,0)(0,1,1) looks almost exactly
like how we previously described the ACF and PACF plots of the
stationerized data (ggtsdisplay(cons\_fsld)). This gives us an idea that
ARIMA(0,1,0)(0,1,1) is more practical for forecasting purposes. Let's
compare forecasts of it with ARIMA(2,1,1)(0,1,3).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Here in this part, we will compare ARIMA(2,1,1)(0,1,3) and (0,1,0)(0,1,1).}
\NormalTok{arima_manual_fc=}\KeywordTok{forecast}\NormalTok{(arima_manual, }\DataTypeTok{h=}\DecValTok{24}\NormalTok{)}
\KeywordTok{autoplot}\NormalTok{(}\KeywordTok{window}\NormalTok{(cons_log,}\DataTypeTok{start=}\DecValTok{2008}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual_fc,}\DataTypeTok{series=}\StringTok{"ARIMA(2,1,1)(0,1,3)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(}\KeywordTok{log}\NormalTok{(cons_test),}\DataTypeTok{series=}\StringTok{"Consumption test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Model vs Test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{)}\OperatorTok{+}\KeywordTok{ylab}\NormalTok{(}\StringTok{"Logarithm of consumption"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-21-1.pdf}

We can see that point forecast of ARIMA(2,1,1)(0,1,3) is very
successful, but its forecast interval is too wide due to the fact that
it has very high variance, so that it implies a range of stagnant to
declining trend (lower bound) to an exponential growth in consumption
(upper bound), which in practice does not make sense. Let's see how
ARIMA(0,1,0)(0,1,1) will forecast:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arima_manual2_fc=}\KeywordTok{forecast}\NormalTok{(arima_manual2, }\DataTypeTok{h=}\DecValTok{24}\NormalTok{)}
\KeywordTok{autoplot}\NormalTok{(}\KeywordTok{window}\NormalTok{(cons_log,}\DataTypeTok{start=}\DecValTok{2008}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual2_fc,}\DataTypeTok{series=}\StringTok{"ARIMA (0,1,0)(0,1,1)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(}\KeywordTok{log}\NormalTok{(cons_test),}\DataTypeTok{series=}\StringTok{"Consumption test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Model vs Test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{)}\OperatorTok{+}\KeywordTok{ylab}\NormalTok{(}\StringTok{"Logarithm of consumption"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-22-1.pdf}

As expected, point forecast is slightly worse compared to
ARIMA(2,1,1)(0,1,3), but, most importantly, its variance is fair, so
that its forecast interval is much narrower. This model is statistically
confident that consumption will continue to grow. Point forecast
comparison can be seen by the below code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{autoplot}\NormalTok{(}\KeywordTok{window}\NormalTok{(cons_log,}\DataTypeTok{start=}\DecValTok{2008}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual_fc,}\DataTypeTok{series=}\StringTok{"ARIMA (2,1,1)(0,1,3)"}\NormalTok{, }\DataTypeTok{PI=}\OtherTok{FALSE}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual2_fc,}\DataTypeTok{series=}\StringTok{"ARIMA (0,1,0)(0,1,1)"}\NormalTok{, }\DataTypeTok{PI=}\OtherTok{FALSE}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(}\KeywordTok{log}\NormalTok{(cons_test),}\DataTypeTok{series=}\StringTok{"Consumption test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Comparison of ARIMA models"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{)}\OperatorTok{+}\KeywordTok{ylab}\NormalTok{(}\StringTok{"Logarithm of consumption"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-23-1.pdf}

And the below code shows how better the forecast interval of
ARIMA(0,1,0)(0,1,1) is, compared to ARIMA(2,1,1)(0,1,3).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{autoplot}\NormalTok{(}\KeywordTok{window}\NormalTok{(cons_log,}\DataTypeTok{start=}\DecValTok{2008}\NormalTok{))}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual_fc,}\DataTypeTok{series=}\StringTok{"ARIMA (2,1,1)(0,1,3)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(arima_manual2_fc,}\DataTypeTok{series=}\StringTok{"ARIMA (0,1,0)(0,1,1)"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{autolayer}\NormalTok{(}\KeywordTok{log}\NormalTok{(cons_test),}\DataTypeTok{series=}\StringTok{"Consumption test set"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Comparison of ARIMA models"}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{)}\OperatorTok{+}\KeywordTok{ylab}\NormalTok{(}\StringTok{"Logarithm of consumption"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Bias_variance_tradeoff_in_time_series_files/figure-latex/unnamed-chunk-24-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## - Conclusion: ARIMA(0,1,0)(0,1,1) has much narrower forecast interval. Therefore, we opt for that one.}
\end{Highlighting}
\end{Shaded}

\hypertarget{conclusion}{%
\paragraph{Conclusion}\label{conclusion}}

By visually inspecting ACF and PACF plots of the stationerized data and
comparing it with theoretical ACF and PACF plots, a more simplified
model with less variance is built. This proves the fact that the
best-fitting model that is found by the use of train data does not
necessarily mean that it is also the most accurate one for forecasting.
In most of the cases, due to bias-variance tradeoff, a more simplified,
and therefore a more generalized model gives much more practical
outcome.

\end{document}
